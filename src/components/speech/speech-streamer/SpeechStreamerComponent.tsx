import React, { useState, useEffect, useRef, forwardRef, useImperativeHandle } from 'react';

interface WordInfo {
  word: string;
  startTime: string;
  endTime: string;
}

interface SpeechStreamerResponse {
  result?: {
    word: string;
    start: number;
    end: number;
    conf: number;
  }[];
  text?: string;
  partial?: string;
  type?: string;
  transcript?: string;
  words?: WordInfo[];
  isFinal?: boolean;
}

export interface SpeechStreamerRef {
  sendAudio: (audioData: ArrayBuffer) => void;
  isConnected: () => boolean;
}

const SpeechStreamerComponent = forwardRef<SpeechStreamerRef, {}>((props, ref) => {
  const [transcript, setTranscript] = useState('');
  const [visemes, setVisemes] = useState<SpeechStreamerResponse['result']>([]);
  const socketRef = useRef<WebSocket | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const audioQueueRef = useRef<ArrayBuffer[]>([]);
  const processingRef = useRef(false);

  const connectToSpeechStreamer = () => {
    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
      console.log('SpeechStreamer serverin…ô artƒ±q qo≈üulub');
      return;
    }

    try {
      console.log('SpeechStreamer serverin…ô qo≈üulmaƒüa c…ôhd edilir...');
      const ws = new WebSocket('ws://localhost:3001');
      socketRef.current = ws;

      ws.onopen = () => {
        console.log('SpeechStreamer serverin…ô qo≈üuldu');
        setIsConnected(true);
        processAudioQueue();
      };

      ws.onmessage = (event) => {
        try {
          const data: SpeechStreamerResponse = JSON.parse(event.data);
          
          // Add a detailed log for transcription type messages
          if (data.type === 'transcription') {
            console.log('RAW TRANSCRIPTION DATA:', JSON.stringify(data, null, 2));
          }

          if (data.result) {
            console.log('‚úÖ SpeechStreamer Tanƒ±nmƒ±≈ü m…ôtn (K√∂hn…ô format):', data.text);
            console.log('üìä SpeechStreamer Viseme m…ôlumatlarƒ± (K√∂hn…ô format):', data.result);
            setVisemes(data.result);
            setTranscript(data.text || '');
          } else if (data.partial) {
            console.log('üîÑ SpeechStreamer Qism…ôn tanƒ±nma (K√∂hn…ô format):', data.partial);
            setTranscript(data.partial || '');

          } else if (data.type === 'transcription' && typeof data.transcript === 'string') {
            console.log('üì© SpeechStreamer SpeechStreamer cavabƒ± (Yeni Format):', data);
            setTranscript(data.transcript || ''); // √úmumi transkripti yenil…ôyirik
          } else {
            console.log('üì© SpeechStreamer SpeechStreamer cavabƒ± (Format t…ôyin edilm…ôdi v…ô ya f…ôrqli k√∂hn…ô format):', data);
          }
        } catch (error) {
          console.error('SpeechStreamer cavabƒ±nƒ±n t…ôhlili zamanƒ± x…ôta:', error);
        }
      };

      ws.onclose = (event) => {
        console.log(`SpeechStreamer serverind…ôn baƒülantƒ± k…ôsildi (${event.code}). Yenid…ôn qo≈üulmaƒüa √ßalƒ±≈üƒ±lƒ±r...`);
        setIsConnected(false);
        
        // Yenid…ôn qo≈üulma
        if (!reconnectTimeoutRef.current) {
          reconnectTimeoutRef.current = setTimeout(() => {
            connectToSpeechStreamer();
            reconnectTimeoutRef.current = null;
          }, 3000);
        }
      };

      ws.onerror = (error) => {
        console.error('WebSocket x…ôtasƒ±:', error);
        setIsConnected(false);
      };
    } catch (error) {
      console.error('SpeechStreamer qo≈üulma x…ôtasƒ±:', error);
      setIsConnected(false);
    }
  };

  // Audio m…ôlumatlar n√∂vb…ôsini i≈ül…ôm…ôk
  const processAudioQueue = () => {
    if (processingRef.current) return;
    if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) return;
    
    processingRef.current = true;
    
    const processNext = () => {
      if (audioQueueRef.current.length === 0) {
        processingRef.current = false;
        return;
      }
      
      const audioData = audioQueueRef.current.shift();
      if (audioData && socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
        try {
          socketRef.current.send(audioData);
          setTimeout(processNext, 10); // N√∂vb…ôti m…ôlumatƒ± emal etm…ôk √º√ß√ºn ki√ßik gecikm…ô
        } catch (error) {
          console.error('Audio g√∂nd…ôrm…ô x…ôtasƒ±:', error);
          processingRef.current = false;
        }
      } else {
        processingRef.current = false;
      }
    };
    
    processNext();
  };

  // Ref vasit…ôsil…ô metodlarƒ± t…ôqdim etm…ôk
  useImperativeHandle(ref, () => ({
    sendAudio: (audioData: ArrayBuffer) => {
      if (!isConnected) {
        if (socketRef.current?.readyState !== WebSocket.OPEN) {
          console.log('SpeechStreamer serverin…ô qo≈üulmaƒüa √ßalƒ±≈üƒ±lƒ±r...');
          connectToSpeechStreamer();
        }
      }
      
      // Audio datanƒ± n√∂vb…ôy…ô …ôlav…ô et
      audioQueueRef.current.push(audioData);
      
      // N√∂vb…ôni emal etm…ôy…ô ba≈üla
      if (!processingRef.current) {
        processAudioQueue();
      }
    },
    isConnected: () => isConnected
  }));

  // ƒ∞lk y√ºkl…ôm…ô zamanƒ± WebSocket baƒülantƒ±sƒ±nƒ± yarat
  useEffect(() => {
    connectToSpeechStreamer();

    return () => {
      if (socketRef.current) {
        socketRef.current.close();
      }
      if (reconnectTimeoutRef.current) {
        clearTimeout(reconnectTimeoutRef.current);
      }
    };
  }, []); // Bo≈ü dependency array, yalnƒ±z mount v…ô unmount zamanƒ± i≈ül…ôyir

  return (
      <></>
  );
});

export default SpeechStreamerComponent;
export type { SpeechStreamerResponse };
